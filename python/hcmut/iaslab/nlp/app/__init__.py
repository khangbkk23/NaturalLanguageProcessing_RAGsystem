#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Há»‡ thá»‘ng xá»­ lÃ½ Ä‘áº·t mÃ³n Äƒn online - NLP Assignment
Pháº§n I: VÄƒn pháº¡m, Sinh cÃ¢u, vÃ  Parser

MSSV: 2311402
Há» vÃ  tÃªn: BÃ¹i Tráº§n Duy Khang
CÃ¡ch cháº¡y: python __init__.py
"""

import os
import sys


sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from nlp.app import CFGrammar, SentenceGenerator, Parser


def setup():
    """Táº¡o cÃ¡c thÆ° má»¥c vÃ  file cáº§n thiáº¿t"""
    # Táº¡o thÆ° má»¥c
    for dir_name in ['input', 'output']:
        os.makedirs(dir_name, exist_ok=True)
    
    input_file = 'input/sentences.txt'
    if not os.path.exists(input_file):
        print(f"[Setup] Táº¡o file input máº«u: {input_file}")
        samples = [
            "tÃ´i muá»‘n Ä‘áº·t 2 pháº§n phá»Ÿ bÃ²",
            "cÃ³ mÃ³n trÃ  sá»¯a khÃ´ng",
            "thÃªm 1 ly cÃ  phÃª vÃ o Ä‘Æ¡n nhÃ©",
            "tÃ´i muá»‘n há»§y mÃ³n gÃ  rÃ¡n",
            "phá»Ÿ bÃ² Ä‘áº¯t khÃ´ng",
            "bÃ¢y giá» tÃ´i muá»‘n Ä‘áº·t 3 tÃ´ bÃºn cháº£",
            "anh Ä‘Ã£ Ä‘áº·t mÃ³n rá»“i",
            "mÃ¬nh thÃ­ch cÆ¡m gÃ  láº¯m",
            "xem menu nhÃ©",
            "cÃ¢u nÃ y khÃ´ng há»£p lá»‡ xyz abc"
        ]
        with open(input_file, 'w', encoding='utf-8') as f:
            for s in samples:
                f.write(s + '\n')


def main():
    
    # Setup
    setup()
    
    # =========================================================================
    # BÆ¯á»šC 2.1: VIáº¾T VÄ‚N PHáº M
    # =========================================================================
    print("[BÆ¯á»šC 2.1] VIáº¾T VÄ‚N PHáº M")
    print("-" * 70)
    
    grammar_file = os.path.join('nlp', 'rule', 'parser.txt')
    grammar = CFGrammar(grammar_file)
    
    stats = grammar.get_stats()
    print(f"âœ“ ÄÃ£ load: {stats['non_terminals']} non-terminals, "
          f"{stats['terminals']} terminals, {stats['rules']} rules")
    
    grammar.save_to_file('output/grammar.txt')
    print()
    
    # =========================================================================
    # BÆ¯á»šC 2.2: SINH CÃ‚U
    # =========================================================================
    print("[BÆ¯á»šC 2.2] SINH CÃ‚U")
    print("-" * 70)
    
    generator = SentenceGenerator(grammar)
    
    # Sinh 500 cÃ¢u (cÃ³ thá»ƒ tÄƒng lÃªn 10000)
    n = 500
    print(f"Äang sinh {n} cÃ¢u...")
    sentences = generator.generate_multiple(n, verbose=False)
    
    generator.save_to_file(sentences, 'output/samples.txt')
    print(f"âœ“ ÄÃ£ sinh {len(sentences)} cÃ¢u")
    
    # Hiá»ƒn thá»‹ máº«u
    print("\nMá»™t sá»‘ cÃ¢u vÃ­ dá»¥:")
    for i, s in enumerate(sentences[:8], 1):
        print(f"  {i}. {s}")
    print()
    
    # =========================================================================
    # BÆ¯á»šC 2.3: PARSE CÃ‚U
    # =========================================================================
    print("[BÆ¯á»šC 2.3] PARSE CÃ‚U")
    print("-" * 70)
    
    parser = Parser(grammar)
    total, valid = parser.parse_file('input/sentences.txt', 
                                     'output/parse-results.txt')
    print()
    
    # =========================================================================
    # Tá»”NG Káº¾T
    # =========================================================================
    print("=" * 70)
    print("âœ… HOÃ€N THÃ€NH!")
    print("=" * 70)
    print(f"\nğŸ“Š Káº¿t quáº£:")
    print(f"  â€¢ VÄƒn pháº¡m: {stats['non_terminals']} non-terminals")
    print(f"  â€¢ Sinh cÃ¢u: {len(sentences)} cÃ¢u")
    print(f"  â€¢ Parse: {valid}/{total} cÃ¢u há»£p lá»‡")
    print(f"\nğŸ“ File output:")
    print(f"  â€¢ output/grammar.txt")
    print(f"  â€¢ output/samples.txt")
    print(f"  â€¢ output/parse-results.txt")
    print("\n" + "=" * 70)


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n[!] ÄÃ£ dá»«ng.")
        sys.exit(0)
    except Exception as e:
        print(f"\n[ERROR] {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
